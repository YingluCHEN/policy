#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾æ±‡åŒºæ”¿ç­–URLéªŒè¯å·¥å…·
ç¡®ä¿çˆ¬è™«ç»“æœçš„çœŸå®æ€§å’Œå¯è¿½æº¯æ€§
"""

import requests
import json
import time
import pandas as pd
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import os

class URLVerificationTool:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.verified_urls = []
        self.failed_urls = []

    def verify_single_url(self, url, policy_title=""):
        """éªŒè¯å•ä¸ªURLçš„æœ‰æ•ˆæ€§"""
        try:
            print(f"éªŒè¯: {policy_title[:60]}...")
            response = self.session.get(url, timeout=10)
            
            verification_result = {
                'url': url,
                'policy_title': policy_title,
                'status_code': response.status_code,
                'is_valid': response.status_code == 200,
                'content_length': len(response.content),
                'verification_time': datetime.now().isoformat(),
                'error': None
            }
            
            if response.status_code == 200:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¾æ±‡åŒºæ”¿åºœç½‘ç«™
                is_xuhui_gov = 'xuhui.gov.cn' in url
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
                content_text = response.text.lower()
                has_policy_content = any(keyword in content_text for keyword in [
                    'å¾æ±‡', 'æ”¿ç­–', 'ç”³æŠ¥', 'æ”¯æŒ', 'è¡¥è´´', 'äººæ‰', 'ä¼ä¸š'
                ])
                
                verification_result.update({
                    'is_xuhui_gov': is_xuhui_gov,
                    'has_policy_content': has_policy_content,
                    'quality_score': self.calculate_quality_score(content_text, url)
                })
                
                self.verified_urls.append(verification_result)
                print(f"  âœ… æœ‰æ•ˆ (çŠ¶æ€ç : {response.status_code}, å†…å®¹é•¿åº¦: {len(response.content)})")
            else:
                verification_result['error'] = f"HTTP {response.status_code}"
                self.failed_urls.append(verification_result)
                print(f"  âŒ å¤±æ•ˆ (çŠ¶æ€ç : {response.status_code})")
                
        except Exception as e:
            verification_result = {
                'url': url,
                'policy_title': policy_title,
                'status_code': 0,
                'is_valid': False,
                'content_length': 0,
                'verification_time': datetime.now().isoformat(),
                'error': str(e),
                'is_xuhui_gov': 'xuhui.gov.cn' in url,
                'has_policy_content': False,
                'quality_score': 0
            }
            self.failed_urls.append(verification_result)
            print(f"  âŒ å¤±è´¥ (é”™è¯¯: {str(e)})")
        
        return verification_result

    def calculate_quality_score(self, content_text, url):
        """è®¡ç®—URLå†…å®¹è´¨é‡è¯„åˆ†"""
        score = 0
        
        # åŸºç¡€åˆ†æ•°
        if 'xuhui.gov.cn' in url:
            score += 20
        
        # æ”¿ç­–å…³é”®è¯
        policy_keywords = ['ç”³æŠ¥', 'æ”¯æŒ', 'è¡¥è´´', 'å¥–åŠ±', 'èµ„åŠ©', 'æ”¿ç­–', 'æ¡ä»¶', 'è¦æ±‚']
        for keyword in policy_keywords:
            if keyword in content_text:
                score += 5
        
        # å…·ä½“æ•°é¢
        if any(term in content_text for term in ['ä¸‡å…ƒ', 'äº¿å…ƒ', 'ç™¾ä¸‡']):
            score += 10
        
        # äººæ‰ç›¸å…³
        talent_keywords = ['äººæ‰', 'åšå£«', 'ç¡•å£«', 'ä¸“å®¶', 'å¼•è¿›']
        for keyword in talent_keywords:
            if keyword in content_text:
                score += 3
        
        # AIç›¸å…³
        ai_keywords = ['äººå·¥æ™ºèƒ½', 'ai', 'ç®—æ³•', 'å¤§æ¨¡å‹', 'æ™ºèƒ½']
        for keyword in ai_keywords:
            if keyword in content_text:
                score += 3
        
        return min(score, 100)  # æœ€é«˜100åˆ†

    def verify_from_json_file(self, json_file_path):
        """ä»JSONæ–‡ä»¶ä¸­è¯»å–æ”¿ç­–æ•°æ®å¹¶éªŒè¯URL"""
        print(f"æ­£åœ¨ä» {json_file_path} è¯»å–æ•°æ®...")
        
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            policies = data.get('policies', [])
            print(f"æ‰¾åˆ° {len(policies)} ä¸ªæ”¿ç­–éœ€è¦éªŒè¯")
            
            # å¹¶å‘éªŒè¯URL
            with ThreadPoolExecutor(max_workers=5) as executor:
                future_to_policy = {
                    executor.submit(self.verify_single_url, policy['url'], policy['title']): policy 
                    for policy in policies if 'url' in policy
                }
                
                for future in as_completed(future_to_policy):
                    try:
                        result = future.result()
                    except Exception as e:
                        print(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                    time.sleep(0.5)
                    
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return

    def verify_sample_urls(self):
        """éªŒè¯ä¸€äº›æ ·æœ¬URL"""
        sample_urls = [
            {
                'url': 'https://www.xuhui.gov.cn/xxgk/portal/article/detail?id=8a4c0c0692292eab0194a6f4d71614b0',
                'title': 'å¾æ±‡åŒºå…³äºæ¨åŠ¨äººå·¥æ™ºèƒ½äº§ä¸šé«˜è´¨é‡å‘å±•çš„è‹¥å¹²æ„è§'
            },
            {
                'url': 'https://www.xuhui.gov.cn/xxgk/portal/article/detail?id=8a4c0c0692292eab0194a6f27fb814ac',
                'title': 'å¾æ±‡åŒºå…³äºæ¨åŠ¨å…·èº«æ™ºèƒ½äº§ä¸šå‘å±•çš„è‹¥å¹²æ„è§'
            },
            {
                'url': 'https://www.xuhui.gov.cn/xxgk/portal/article/detail?id=8a4c0c0692292eab019384dc95a70aed',
                'title': 'å…³äºæ”¯æŒä¸Šæµ·å¸‚ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åˆ›æ–°ç”Ÿæ€å…ˆå¯¼åŒºçš„è‹¥å¹²æªæ–½'
            },
            {
                'url': 'https://www.xuhui.gov.cn/xxgk/portal/article/organizationArticle?code=xhxxgk_wbj_kjw&page=1',
                'title': 'å¾æ±‡åŒºç§‘å§”æ”¿ç­–åˆ—è¡¨é¡µé¢'
            },
            {
                'url': 'https://www.xuhui.gov.cn',
                'title': 'å¾æ±‡åŒºæ”¿åºœå®˜ç½‘é¦–é¡µ'
            }
        ]
        
        print("éªŒè¯æ ·æœ¬URL...")
        for sample in sample_urls:
            self.verify_single_url(sample['url'], sample['title'])
            time.sleep(1)

    def generate_verification_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        os.makedirs('data', exist_ok=True)
        
        total_urls = len(self.verified_urls) + len(self.failed_urls)
        valid_count = len(self.verified_urls)
        invalid_count = len(self.failed_urls)
        
        # ç»Ÿè®¡åˆ†æ
        quality_scores = [url['quality_score'] for url in self.verified_urls if 'quality_score' in url]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_content = f"""
# å¾æ±‡åŒºæ”¿ç­–URLéªŒè¯æŠ¥å‘Š

## éªŒè¯æ¦‚è§ˆ
- **éªŒè¯æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ€»URLæ•°é‡**: {total_urls}
- **æœ‰æ•ˆURLæ•°é‡**: {valid_count} ({valid_count/total_urls*100:.1f}%)
- **å¤±æ•ˆURLæ•°é‡**: {invalid_count} ({invalid_count/total_urls*100:.1f}%)
- **å¹³å‡è´¨é‡è¯„åˆ†**: {avg_quality:.1f}/100

## éªŒè¯ç»“æœè¯¦æƒ…

### âœ… æœ‰æ•ˆURL ({valid_count}ä¸ª)
"""
        
        for i, url_info in enumerate(self.verified_urls, 1):
            report_content += f"""
**{i}. {url_info['policy_title']}**
- URL: {url_info['url']}
- çŠ¶æ€ç : {url_info['status_code']}
- å†…å®¹é•¿åº¦: {url_info['content_length']} å­—èŠ‚
- è´¨é‡è¯„åˆ†: {url_info.get('quality_score', 0)}/100
- éªŒè¯æ—¶é—´: {url_info['verification_time']}
"""

        if self.failed_urls:
            report_content += f"\n### âŒ å¤±æ•ˆURL ({invalid_count}ä¸ª)\n"
            for i, url_info in enumerate(self.failed_urls, 1):
                report_content += f"""
**{i}. {url_info['policy_title']}**
- URL: {url_info['url']}
- é”™è¯¯ä¿¡æ¯: {url_info['error']}
- éªŒè¯æ—¶é—´: {url_info['verification_time']}
"""

        # ä¿å­˜æŠ¥å‘Š
        with open('data/url_verification_report.md', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # å¯¼å‡ºéªŒè¯æ•°æ®
        all_results = self.verified_urls + self.failed_urls
        
        # JSONæ ¼å¼
        with open('data/url_verification_results.json', 'w', encoding='utf-8') as f:
            json.dump({
                'verification_time': datetime.now().isoformat(),
                'summary': {
                    'total_urls': total_urls,
                    'valid_urls': valid_count,
                    'invalid_urls': invalid_count,
                    'success_rate': valid_count/total_urls*100 if total_urls > 0 else 0,
                    'average_quality_score': avg_quality
                },
                'results': all_results
            }, f, ensure_ascii=False, indent=2)
        
        # CSVæ ¼å¼
        df = pd.DataFrame(all_results)
        df.to_csv('data/url_verification_results.csv', index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ“Š éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ:")
        print(f"   ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: data/url_verification_report.md")
        print(f"   ğŸ“Š éªŒè¯æ•°æ®: data/url_verification_results.json")
        print(f"   ğŸ“Š è¡¨æ ¼æ•°æ®: data/url_verification_results.csv")
        print(f"\nâœ… URLæœ‰æ•ˆç‡: {valid_count}/{total_urls} ({valid_count/total_urls*100:.1f}%)")
        print(f"ğŸ“ˆ å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality:.1f}/100")

def main():
    print("ğŸ” å¾æ±‡åŒºæ”¿ç­–URLéªŒè¯å·¥å…·")
    print("=" * 50)
    
    verifier = URLVerificationTool()
    
    # é€‰æ‹©éªŒè¯æ¨¡å¼
    print("è¯·é€‰æ‹©éªŒè¯æ¨¡å¼:")
    print("1. éªŒè¯æ ·æœ¬URL (æ¨è)")
    print("2. éªŒè¯JSONæ–‡ä»¶ä¸­çš„æ‰€æœ‰URL")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2): ").strip()
    
    if choice == "1":
        verifier.verify_sample_urls()
    elif choice == "2":
        json_files = [
            'data/enhanced_talent_policies.json',
            'data/comprehensive_talent_policies.json',
            'data/talent_policies.json'
        ]
        
        available_files = [f for f in json_files if os.path.exists(f)]
        
        if available_files:
            print(f"æ‰¾åˆ°ä»¥ä¸‹æ•°æ®æ–‡ä»¶:")
            for i, file in enumerate(available_files, 1):
                print(f"  {i}. {file}")
            
            file_choice = input("è¯·é€‰æ‹©æ–‡ä»¶ç¼–å·: ").strip()
            try:
                selected_file = available_files[int(file_choice) - 1]
                verifier.verify_from_json_file(selected_file)
            except (ValueError, IndexError):
                print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤æ–‡ä»¶")
                verifier.verify_from_json_file(available_files[0])
        else:
            print("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œæ”¹ä¸ºéªŒè¯æ ·æœ¬URL")
            verifier.verify_sample_urls()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æ ·æœ¬URLéªŒè¯")
        verifier.verify_sample_urls()
    
    # ç”ŸæˆæŠ¥å‘Š
    verifier.generate_verification_report()

if __name__ == "__main__":
    main() 